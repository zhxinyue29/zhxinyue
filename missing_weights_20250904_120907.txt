âŒ å®Œæ•´ç¼ºå¤±æƒé‡åˆ—è¡¨
ç”Ÿæˆæ—¶é—´: 20250904_120907
æ¨¡å‹è·¯å¾„: /home/liyakun/twitter-stock-prediction/models/model2/best_model.pt
æ€»æƒé‡æ•°: 317
åŒ¹é…æƒé‡æ•°: 84
ç¼ºå¤±æƒé‡æ•°: 233

=== æŒ‰ç±»å‹åˆ†ç»„çš„ç¼ºå¤±æƒé‡ ===

ğŸ” final_norm (å…±1é¡¹):
    1. final_norm.weight (å½¢çŠ¶: (1536,))

ğŸ” input_proj (å…±3é¡¹):
    1. input_proj.0.bias (å½¢çŠ¶: (1536,))
    2. input_proj.0.weight (å½¢çŠ¶: (1536, 773))
    3. input_proj.2.weight (å½¢çŠ¶: (1536,))

ğŸ” layers (å…±224é¡¹):
    1. layers.0.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
    2. layers.0.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
    3. layers.0.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
    4. layers.0.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
    5. layers.0.attention_norm.weight (å½¢çŠ¶: (1536,))
    6. layers.0.ffn_norm.weight (å½¢çŠ¶: (1536,))
    7. layers.0.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
    8. layers.0.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
    9. layers.1.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
   10. layers.1.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
   11. layers.1.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
   12. layers.1.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
   13. layers.1.attention_norm.weight (å½¢çŠ¶: (1536,))
   14. layers.1.ffn_norm.weight (å½¢çŠ¶: (1536,))
   15. layers.1.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
   16. layers.1.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
   17. layers.10.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
   18. layers.10.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
   19. layers.10.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
   20. layers.10.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
   21. layers.10.attention_norm.weight (å½¢çŠ¶: (1536,))
   22. layers.10.ffn_norm.weight (å½¢çŠ¶: (1536,))
   23. layers.10.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
   24. layers.10.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
   25. layers.11.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
   26. layers.11.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
   27. layers.11.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
   28. layers.11.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
   29. layers.11.attention_norm.weight (å½¢çŠ¶: (1536,))
   30. layers.11.ffn_norm.weight (å½¢çŠ¶: (1536,))
   31. layers.11.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
   32. layers.11.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
   33. layers.12.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
   34. layers.12.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
   35. layers.12.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
   36. layers.12.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
   37. layers.12.attention_norm.weight (å½¢çŠ¶: (1536,))
   38. layers.12.ffn_norm.weight (å½¢çŠ¶: (1536,))
   39. layers.12.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
   40. layers.12.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
   41. layers.13.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
   42. layers.13.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
   43. layers.13.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
   44. layers.13.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
   45. layers.13.attention_norm.weight (å½¢çŠ¶: (1536,))
   46. layers.13.ffn_norm.weight (å½¢çŠ¶: (1536,))
   47. layers.13.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
   48. layers.13.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
   49. layers.14.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
   50. layers.14.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
   51. layers.14.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
   52. layers.14.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
   53. layers.14.attention_norm.weight (å½¢çŠ¶: (1536,))
   54. layers.14.ffn_norm.weight (å½¢çŠ¶: (1536,))
   55. layers.14.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
   56. layers.14.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
   57. layers.15.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
   58. layers.15.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
   59. layers.15.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
   60. layers.15.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
   61. layers.15.attention_norm.weight (å½¢çŠ¶: (1536,))
   62. layers.15.ffn_norm.weight (å½¢çŠ¶: (1536,))
   63. layers.15.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
   64. layers.15.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
   65. layers.16.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
   66. layers.16.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
   67. layers.16.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
   68. layers.16.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
   69. layers.16.attention_norm.weight (å½¢çŠ¶: (1536,))
   70. layers.16.ffn_norm.weight (å½¢çŠ¶: (1536,))
   71. layers.16.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
   72. layers.16.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
   73. layers.17.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
   74. layers.17.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
   75. layers.17.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
   76. layers.17.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
   77. layers.17.attention_norm.weight (å½¢çŠ¶: (1536,))
   78. layers.17.ffn_norm.weight (å½¢çŠ¶: (1536,))
   79. layers.17.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
   80. layers.17.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
   81. layers.18.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
   82. layers.18.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
   83. layers.18.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
   84. layers.18.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
   85. layers.18.attention_norm.weight (å½¢çŠ¶: (1536,))
   86. layers.18.ffn_norm.weight (å½¢çŠ¶: (1536,))
   87. layers.18.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
   88. layers.18.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
   89. layers.19.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
   90. layers.19.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
   91. layers.19.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
   92. layers.19.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
   93. layers.19.attention_norm.weight (å½¢çŠ¶: (1536,))
   94. layers.19.ffn_norm.weight (å½¢çŠ¶: (1536,))
   95. layers.19.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
   96. layers.19.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
   97. layers.2.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
   98. layers.2.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
   99. layers.2.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  100. layers.2.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
  101. layers.2.attention_norm.weight (å½¢çŠ¶: (1536,))
  102. layers.2.ffn_norm.weight (å½¢çŠ¶: (1536,))
  103. layers.2.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
  104. layers.2.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
  105. layers.20.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
  106. layers.20.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
  107. layers.20.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  108. layers.20.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
  109. layers.20.attention_norm.weight (å½¢çŠ¶: (1536,))
  110. layers.20.ffn_norm.weight (å½¢çŠ¶: (1536,))
  111. layers.20.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
  112. layers.20.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
  113. layers.21.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
  114. layers.21.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
  115. layers.21.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  116. layers.21.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
  117. layers.21.attention_norm.weight (å½¢çŠ¶: (1536,))
  118. layers.21.ffn_norm.weight (å½¢çŠ¶: (1536,))
  119. layers.21.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
  120. layers.21.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
  121. layers.22.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
  122. layers.22.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
  123. layers.22.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  124. layers.22.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
  125. layers.22.attention_norm.weight (å½¢çŠ¶: (1536,))
  126. layers.22.ffn_norm.weight (å½¢çŠ¶: (1536,))
  127. layers.22.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
  128. layers.22.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
  129. layers.23.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
  130. layers.23.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
  131. layers.23.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  132. layers.23.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
  133. layers.23.attention_norm.weight (å½¢çŠ¶: (1536,))
  134. layers.23.ffn_norm.weight (å½¢çŠ¶: (1536,))
  135. layers.23.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
  136. layers.23.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
  137. layers.24.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
  138. layers.24.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
  139. layers.24.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  140. layers.24.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
  141. layers.24.attention_norm.weight (å½¢çŠ¶: (1536,))
  142. layers.24.ffn_norm.weight (å½¢çŠ¶: (1536,))
  143. layers.24.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
  144. layers.24.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
  145. layers.25.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
  146. layers.25.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
  147. layers.25.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  148. layers.25.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
  149. layers.25.attention_norm.weight (å½¢çŠ¶: (1536,))
  150. layers.25.ffn_norm.weight (å½¢çŠ¶: (1536,))
  151. layers.25.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
  152. layers.25.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
  153. layers.26.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
  154. layers.26.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
  155. layers.26.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  156. layers.26.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
  157. layers.26.attention_norm.weight (å½¢çŠ¶: (1536,))
  158. layers.26.ffn_norm.weight (å½¢çŠ¶: (1536,))
  159. layers.26.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
  160. layers.26.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
  161. layers.27.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
  162. layers.27.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
  163. layers.27.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  164. layers.27.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
  165. layers.27.attention_norm.weight (å½¢çŠ¶: (1536,))
  166. layers.27.ffn_norm.weight (å½¢çŠ¶: (1536,))
  167. layers.27.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
  168. layers.27.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
  169. layers.3.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
  170. layers.3.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
  171. layers.3.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  172. layers.3.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
  173. layers.3.attention_norm.weight (å½¢çŠ¶: (1536,))
  174. layers.3.ffn_norm.weight (å½¢çŠ¶: (1536,))
  175. layers.3.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
  176. layers.3.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
  177. layers.4.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
  178. layers.4.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
  179. layers.4.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  180. layers.4.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
  181. layers.4.attention_norm.weight (å½¢çŠ¶: (1536,))
  182. layers.4.ffn_norm.weight (å½¢çŠ¶: (1536,))
  183. layers.4.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
  184. layers.4.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
  185. layers.5.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
  186. layers.5.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
  187. layers.5.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  188. layers.5.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
  189. layers.5.attention_norm.weight (å½¢çŠ¶: (1536,))
  190. layers.5.ffn_norm.weight (å½¢çŠ¶: (1536,))
  191. layers.5.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
  192. layers.5.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
  193. layers.6.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
  194. layers.6.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
  195. layers.6.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  196. layers.6.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
  197. layers.6.attention_norm.weight (å½¢çŠ¶: (1536,))
  198. layers.6.ffn_norm.weight (å½¢çŠ¶: (1536,))
  199. layers.6.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
  200. layers.6.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
  201. layers.7.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
  202. layers.7.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
  203. layers.7.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  204. layers.7.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
  205. layers.7.attention_norm.weight (å½¢çŠ¶: (1536,))
  206. layers.7.ffn_norm.weight (å½¢çŠ¶: (1536,))
  207. layers.7.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
  208. layers.7.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
  209. layers.8.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
  210. layers.8.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
  211. layers.8.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  212. layers.8.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
  213. layers.8.attention_norm.weight (å½¢çŠ¶: (1536,))
  214. layers.8.ffn_norm.weight (å½¢çŠ¶: (1536,))
  215. layers.8.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
  216. layers.8.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
  217. layers.9.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
  218. layers.9.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
  219. layers.9.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  220. layers.9.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
  221. layers.9.attention_norm.weight (å½¢çŠ¶: (1536,))
  222. layers.9.ffn_norm.weight (å½¢çŠ¶: (1536,))
  223. layers.9.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
  224. layers.9.mlp.up_proj.bias (å½¢çŠ¶: (8960,))

ğŸ” output_layer (å…±2é¡¹):
    1. output_layer.bias (å½¢çŠ¶: (1,))
    2. output_layer.weight (å½¢çŠ¶: (1, 1536))

ğŸ” rotary_emb (å…±3é¡¹):
    1. rotary_emb.cos_cached (å½¢çŠ¶: (1, 1, 4096, 64))
    2. rotary_emb.inv_freq (å½¢çŠ¶: (32,))
    3. rotary_emb.sin_cached (å½¢çŠ¶: (1, 1, 4096, 64))

ğŸ” æ‰€æœ‰æ¨¡å‹é”®:
  1. input_proj.0.weight (å½¢çŠ¶: (1536, 773))
  2. input_proj.0.bias (å½¢çŠ¶: (1536,))
  3. input_proj.2.weight (å½¢çŠ¶: (1536,))
  4. rotary_emb.inv_freq (å½¢çŠ¶: (32,))
  5. rotary_emb.cos_cached (å½¢çŠ¶: (1, 1, 4096, 64))
  6. rotary_emb.sin_cached (å½¢çŠ¶: (1, 1, 4096, 64))
  7. layers.0.attention_norm.weight (å½¢çŠ¶: (1536,))
  8. layers.0.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  9. layers.0.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
 10. layers.0.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
 11. layers.0.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
 12. layers.0.ffn_norm.weight (å½¢çŠ¶: (1536,))
 13. layers.0.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
 14. layers.0.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
 15. layers.0.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
 16. layers.0.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
 17. layers.0.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
 18. layers.1.attention_norm.weight (å½¢çŠ¶: (1536,))
 19. layers.1.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
 20. layers.1.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
 21. layers.1.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
 22. layers.1.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
 23. layers.1.ffn_norm.weight (å½¢çŠ¶: (1536,))
 24. layers.1.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
 25. layers.1.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
 26. layers.1.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
 27. layers.1.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
 28. layers.1.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
 29. layers.2.attention_norm.weight (å½¢çŠ¶: (1536,))
 30. layers.2.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
 31. layers.2.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
 32. layers.2.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
 33. layers.2.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
 34. layers.2.ffn_norm.weight (å½¢çŠ¶: (1536,))
 35. layers.2.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
 36. layers.2.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
 37. layers.2.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
 38. layers.2.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
 39. layers.2.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
 40. layers.3.attention_norm.weight (å½¢çŠ¶: (1536,))
 41. layers.3.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
 42. layers.3.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
 43. layers.3.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
 44. layers.3.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
 45. layers.3.ffn_norm.weight (å½¢çŠ¶: (1536,))
 46. layers.3.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
 47. layers.3.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
 48. layers.3.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
 49. layers.3.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
 50. layers.3.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
 51. layers.4.attention_norm.weight (å½¢çŠ¶: (1536,))
 52. layers.4.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
 53. layers.4.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
 54. layers.4.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
 55. layers.4.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
 56. layers.4.ffn_norm.weight (å½¢çŠ¶: (1536,))
 57. layers.4.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
 58. layers.4.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
 59. layers.4.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
 60. layers.4.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
 61. layers.4.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
 62. layers.5.attention_norm.weight (å½¢çŠ¶: (1536,))
 63. layers.5.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
 64. layers.5.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
 65. layers.5.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
 66. layers.5.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
 67. layers.5.ffn_norm.weight (å½¢çŠ¶: (1536,))
 68. layers.5.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
 69. layers.5.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
 70. layers.5.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
 71. layers.5.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
 72. layers.5.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
 73. layers.6.attention_norm.weight (å½¢çŠ¶: (1536,))
 74. layers.6.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
 75. layers.6.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
 76. layers.6.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
 77. layers.6.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
 78. layers.6.ffn_norm.weight (å½¢çŠ¶: (1536,))
 79. layers.6.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
 80. layers.6.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
 81. layers.6.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
 82. layers.6.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
 83. layers.6.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
 84. layers.7.attention_norm.weight (å½¢çŠ¶: (1536,))
 85. layers.7.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
 86. layers.7.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
 87. layers.7.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
 88. layers.7.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
 89. layers.7.ffn_norm.weight (å½¢çŠ¶: (1536,))
 90. layers.7.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
 91. layers.7.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
 92. layers.7.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
 93. layers.7.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
 94. layers.7.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
 95. layers.8.attention_norm.weight (å½¢çŠ¶: (1536,))
 96. layers.8.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
 97. layers.8.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
 98. layers.8.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
 99. layers.8.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
100. layers.8.ffn_norm.weight (å½¢çŠ¶: (1536,))
101. layers.8.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
102. layers.8.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
103. layers.8.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
104. layers.8.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
105. layers.8.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
106. layers.9.attention_norm.weight (å½¢çŠ¶: (1536,))
107. layers.9.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
108. layers.9.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
109. layers.9.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
110. layers.9.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
111. layers.9.ffn_norm.weight (å½¢çŠ¶: (1536,))
112. layers.9.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
113. layers.9.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
114. layers.9.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
115. layers.9.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
116. layers.9.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
117. layers.10.attention_norm.weight (å½¢çŠ¶: (1536,))
118. layers.10.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
119. layers.10.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
120. layers.10.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
121. layers.10.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
122. layers.10.ffn_norm.weight (å½¢çŠ¶: (1536,))
123. layers.10.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
124. layers.10.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
125. layers.10.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
126. layers.10.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
127. layers.10.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
128. layers.11.attention_norm.weight (å½¢çŠ¶: (1536,))
129. layers.11.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
130. layers.11.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
131. layers.11.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
132. layers.11.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
133. layers.11.ffn_norm.weight (å½¢çŠ¶: (1536,))
134. layers.11.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
135. layers.11.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
136. layers.11.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
137. layers.11.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
138. layers.11.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
139. layers.12.attention_norm.weight (å½¢çŠ¶: (1536,))
140. layers.12.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
141. layers.12.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
142. layers.12.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
143. layers.12.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
144. layers.12.ffn_norm.weight (å½¢çŠ¶: (1536,))
145. layers.12.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
146. layers.12.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
147. layers.12.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
148. layers.12.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
149. layers.12.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
150. layers.13.attention_norm.weight (å½¢çŠ¶: (1536,))
151. layers.13.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
152. layers.13.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
153. layers.13.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
154. layers.13.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
155. layers.13.ffn_norm.weight (å½¢çŠ¶: (1536,))
156. layers.13.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
157. layers.13.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
158. layers.13.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
159. layers.13.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
160. layers.13.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
161. layers.14.attention_norm.weight (å½¢çŠ¶: (1536,))
162. layers.14.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
163. layers.14.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
164. layers.14.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
165. layers.14.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
166. layers.14.ffn_norm.weight (å½¢çŠ¶: (1536,))
167. layers.14.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
168. layers.14.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
169. layers.14.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
170. layers.14.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
171. layers.14.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
172. layers.15.attention_norm.weight (å½¢çŠ¶: (1536,))
173. layers.15.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
174. layers.15.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
175. layers.15.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
176. layers.15.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
177. layers.15.ffn_norm.weight (å½¢çŠ¶: (1536,))
178. layers.15.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
179. layers.15.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
180. layers.15.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
181. layers.15.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
182. layers.15.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
183. layers.16.attention_norm.weight (å½¢çŠ¶: (1536,))
184. layers.16.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
185. layers.16.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
186. layers.16.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
187. layers.16.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
188. layers.16.ffn_norm.weight (å½¢çŠ¶: (1536,))
189. layers.16.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
190. layers.16.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
191. layers.16.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
192. layers.16.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
193. layers.16.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
194. layers.17.attention_norm.weight (å½¢çŠ¶: (1536,))
195. layers.17.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
196. layers.17.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
197. layers.17.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
198. layers.17.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
199. layers.17.ffn_norm.weight (å½¢çŠ¶: (1536,))
200. layers.17.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
201. layers.17.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
202. layers.17.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
203. layers.17.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
204. layers.17.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
205. layers.18.attention_norm.weight (å½¢çŠ¶: (1536,))
206. layers.18.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
207. layers.18.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
208. layers.18.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
209. layers.18.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
210. layers.18.ffn_norm.weight (å½¢çŠ¶: (1536,))
211. layers.18.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
212. layers.18.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
213. layers.18.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
214. layers.18.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
215. layers.18.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
216. layers.19.attention_norm.weight (å½¢çŠ¶: (1536,))
217. layers.19.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
218. layers.19.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
219. layers.19.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
220. layers.19.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
221. layers.19.ffn_norm.weight (å½¢çŠ¶: (1536,))
222. layers.19.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
223. layers.19.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
224. layers.19.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
225. layers.19.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
226. layers.19.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
227. layers.20.attention_norm.weight (å½¢çŠ¶: (1536,))
228. layers.20.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
229. layers.20.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
230. layers.20.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
231. layers.20.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
232. layers.20.ffn_norm.weight (å½¢çŠ¶: (1536,))
233. layers.20.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
234. layers.20.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
235. layers.20.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
236. layers.20.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
237. layers.20.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
238. layers.21.attention_norm.weight (å½¢çŠ¶: (1536,))
239. layers.21.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
240. layers.21.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
241. layers.21.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
242. layers.21.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
243. layers.21.ffn_norm.weight (å½¢çŠ¶: (1536,))
244. layers.21.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
245. layers.21.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
246. layers.21.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
247. layers.21.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
248. layers.21.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
249. layers.22.attention_norm.weight (å½¢çŠ¶: (1536,))
250. layers.22.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
251. layers.22.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
252. layers.22.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
253. layers.22.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
254. layers.22.ffn_norm.weight (å½¢çŠ¶: (1536,))
255. layers.22.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
256. layers.22.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
257. layers.22.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
258. layers.22.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
259. layers.22.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
260. layers.23.attention_norm.weight (å½¢çŠ¶: (1536,))
261. layers.23.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
262. layers.23.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
263. layers.23.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
264. layers.23.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
265. layers.23.ffn_norm.weight (å½¢çŠ¶: (1536,))
266. layers.23.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
267. layers.23.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
268. layers.23.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
269. layers.23.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
270. layers.23.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
271. layers.24.attention_norm.weight (å½¢çŠ¶: (1536,))
272. layers.24.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
273. layers.24.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
274. layers.24.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
275. layers.24.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
276. layers.24.ffn_norm.weight (å½¢çŠ¶: (1536,))
277. layers.24.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
278. layers.24.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
279. layers.24.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
280. layers.24.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
281. layers.24.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
282. layers.25.attention_norm.weight (å½¢çŠ¶: (1536,))
283. layers.25.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
284. layers.25.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
285. layers.25.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
286. layers.25.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
287. layers.25.ffn_norm.weight (å½¢çŠ¶: (1536,))
288. layers.25.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
289. layers.25.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
290. layers.25.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
291. layers.25.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
292. layers.25.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
293. layers.26.attention_norm.weight (å½¢çŠ¶: (1536,))
294. layers.26.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
295. layers.26.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
296. layers.26.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
297. layers.26.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
298. layers.26.ffn_norm.weight (å½¢çŠ¶: (1536,))
299. layers.26.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
300. layers.26.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
301. layers.26.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
302. layers.26.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
303. layers.26.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
304. layers.27.attention_norm.weight (å½¢çŠ¶: (1536,))
305. layers.27.attention.q_proj.weight (å½¢çŠ¶: (1536, 1536))
306. layers.27.attention.k_proj.weight (å½¢çŠ¶: (256, 1536))
307. layers.27.attention.v_proj.weight (å½¢çŠ¶: (256, 1536))
308. layers.27.attention.o_proj.weight (å½¢çŠ¶: (1536, 1536))
309. layers.27.ffn_norm.weight (å½¢çŠ¶: (1536,))
310. layers.27.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
311. layers.27.mlp.gate_proj.bias (å½¢çŠ¶: (8960,))
312. layers.27.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
313. layers.27.mlp.up_proj.bias (å½¢çŠ¶: (8960,))
314. layers.27.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
315. final_norm.weight (å½¢çŠ¶: (1536,))
316. output_layer.weight (å½¢çŠ¶: (1, 1536))
317. output_layer.bias (å½¢çŠ¶: (1,))

ğŸ” æ‰€æœ‰æƒé‡é”®:
  1. embed_tokens.weight (å½¢çŠ¶: (151936, 1536))
  2. layers.0.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
  3. layers.0.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
  4. layers.0.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
  5. layers.0.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
  6. layers.0.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
  7. layers.0.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
  8. layers.0.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
  9. layers.0.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
 10. layers.0.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
 11. layers.0.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
 12. layers.0.input_layernorm.weight (å½¢çŠ¶: (1536,))
 13. layers.0.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
 14. layers.1.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
 15. layers.1.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
 16. layers.1.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
 17. layers.1.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
 18. layers.1.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
 19. layers.1.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
 20. layers.1.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
 21. layers.1.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
 22. layers.1.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
 23. layers.1.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
 24. layers.1.input_layernorm.weight (å½¢çŠ¶: (1536,))
 25. layers.1.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
 26. layers.2.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
 27. layers.2.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
 28. layers.2.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
 29. layers.2.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
 30. layers.2.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
 31. layers.2.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
 32. layers.2.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
 33. layers.2.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
 34. layers.2.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
 35. layers.2.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
 36. layers.2.input_layernorm.weight (å½¢çŠ¶: (1536,))
 37. layers.2.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
 38. layers.3.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
 39. layers.3.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
 40. layers.3.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
 41. layers.3.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
 42. layers.3.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
 43. layers.3.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
 44. layers.3.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
 45. layers.3.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
 46. layers.3.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
 47. layers.3.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
 48. layers.3.input_layernorm.weight (å½¢çŠ¶: (1536,))
 49. layers.3.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
 50. layers.4.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
 51. layers.4.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
 52. layers.4.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
 53. layers.4.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
 54. layers.4.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
 55. layers.4.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
 56. layers.4.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
 57. layers.4.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
 58. layers.4.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
 59. layers.4.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
 60. layers.4.input_layernorm.weight (å½¢çŠ¶: (1536,))
 61. layers.4.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
 62. layers.5.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
 63. layers.5.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
 64. layers.5.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
 65. layers.5.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
 66. layers.5.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
 67. layers.5.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
 68. layers.5.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
 69. layers.5.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
 70. layers.5.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
 71. layers.5.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
 72. layers.5.input_layernorm.weight (å½¢çŠ¶: (1536,))
 73. layers.5.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
 74. layers.6.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
 75. layers.6.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
 76. layers.6.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
 77. layers.6.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
 78. layers.6.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
 79. layers.6.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
 80. layers.6.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
 81. layers.6.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
 82. layers.6.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
 83. layers.6.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
 84. layers.6.input_layernorm.weight (å½¢çŠ¶: (1536,))
 85. layers.6.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
 86. layers.7.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
 87. layers.7.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
 88. layers.7.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
 89. layers.7.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
 90. layers.7.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
 91. layers.7.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
 92. layers.7.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
 93. layers.7.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
 94. layers.7.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
 95. layers.7.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
 96. layers.7.input_layernorm.weight (å½¢çŠ¶: (1536,))
 97. layers.7.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
 98. layers.8.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
 99. layers.8.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
100. layers.8.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
101. layers.8.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
102. layers.8.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
103. layers.8.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
104. layers.8.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
105. layers.8.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
106. layers.8.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
107. layers.8.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
108. layers.8.input_layernorm.weight (å½¢çŠ¶: (1536,))
109. layers.8.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
110. layers.9.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
111. layers.9.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
112. layers.9.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
113. layers.9.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
114. layers.9.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
115. layers.9.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
116. layers.9.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
117. layers.9.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
118. layers.9.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
119. layers.9.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
120. layers.9.input_layernorm.weight (å½¢çŠ¶: (1536,))
121. layers.9.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
122. layers.10.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
123. layers.10.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
124. layers.10.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
125. layers.10.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
126. layers.10.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
127. layers.10.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
128. layers.10.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
129. layers.10.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
130. layers.10.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
131. layers.10.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
132. layers.10.input_layernorm.weight (å½¢çŠ¶: (1536,))
133. layers.10.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
134. layers.11.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
135. layers.11.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
136. layers.11.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
137. layers.11.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
138. layers.11.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
139. layers.11.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
140. layers.11.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
141. layers.11.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
142. layers.11.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
143. layers.11.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
144. layers.11.input_layernorm.weight (å½¢çŠ¶: (1536,))
145. layers.11.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
146. layers.12.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
147. layers.12.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
148. layers.12.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
149. layers.12.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
150. layers.12.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
151. layers.12.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
152. layers.12.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
153. layers.12.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
154. layers.12.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
155. layers.12.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
156. layers.12.input_layernorm.weight (å½¢çŠ¶: (1536,))
157. layers.12.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
158. layers.13.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
159. layers.13.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
160. layers.13.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
161. layers.13.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
162. layers.13.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
163. layers.13.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
164. layers.13.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
165. layers.13.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
166. layers.13.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
167. layers.13.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
168. layers.13.input_layernorm.weight (å½¢çŠ¶: (1536,))
169. layers.13.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
170. layers.14.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
171. layers.14.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
172. layers.14.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
173. layers.14.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
174. layers.14.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
175. layers.14.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
176. layers.14.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
177. layers.14.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
178. layers.14.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
179. layers.14.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
180. layers.14.input_layernorm.weight (å½¢çŠ¶: (1536,))
181. layers.14.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
182. layers.15.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
183. layers.15.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
184. layers.15.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
185. layers.15.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
186. layers.15.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
187. layers.15.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
188. layers.15.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
189. layers.15.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
190. layers.15.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
191. layers.15.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
192. layers.15.input_layernorm.weight (å½¢çŠ¶: (1536,))
193. layers.15.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
194. layers.16.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
195. layers.16.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
196. layers.16.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
197. layers.16.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
198. layers.16.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
199. layers.16.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
200. layers.16.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
201. layers.16.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
202. layers.16.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
203. layers.16.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
204. layers.16.input_layernorm.weight (å½¢çŠ¶: (1536,))
205. layers.16.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
206. layers.17.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
207. layers.17.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
208. layers.17.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
209. layers.17.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
210. layers.17.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
211. layers.17.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
212. layers.17.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
213. layers.17.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
214. layers.17.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
215. layers.17.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
216. layers.17.input_layernorm.weight (å½¢çŠ¶: (1536,))
217. layers.17.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
218. layers.18.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
219. layers.18.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
220. layers.18.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
221. layers.18.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
222. layers.18.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
223. layers.18.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
224. layers.18.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
225. layers.18.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
226. layers.18.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
227. layers.18.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
228. layers.18.input_layernorm.weight (å½¢çŠ¶: (1536,))
229. layers.18.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
230. layers.19.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
231. layers.19.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
232. layers.19.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
233. layers.19.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
234. layers.19.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
235. layers.19.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
236. layers.19.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
237. layers.19.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
238. layers.19.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
239. layers.19.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
240. layers.19.input_layernorm.weight (å½¢çŠ¶: (1536,))
241. layers.19.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
242. layers.20.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
243. layers.20.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
244. layers.20.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
245. layers.20.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
246. layers.20.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
247. layers.20.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
248. layers.20.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
249. layers.20.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
250. layers.20.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
251. layers.20.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
252. layers.20.input_layernorm.weight (å½¢çŠ¶: (1536,))
253. layers.20.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
254. layers.21.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
255. layers.21.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
256. layers.21.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
257. layers.21.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
258. layers.21.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
259. layers.21.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
260. layers.21.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
261. layers.21.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
262. layers.21.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
263. layers.21.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
264. layers.21.input_layernorm.weight (å½¢çŠ¶: (1536,))
265. layers.21.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
266. layers.22.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
267. layers.22.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
268. layers.22.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
269. layers.22.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
270. layers.22.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
271. layers.22.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
272. layers.22.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
273. layers.22.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
274. layers.22.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
275. layers.22.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
276. layers.22.input_layernorm.weight (å½¢çŠ¶: (1536,))
277. layers.22.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
278. layers.23.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
279. layers.23.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
280. layers.23.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
281. layers.23.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
282. layers.23.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
283. layers.23.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
284. layers.23.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
285. layers.23.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
286. layers.23.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
287. layers.23.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
288. layers.23.input_layernorm.weight (å½¢çŠ¶: (1536,))
289. layers.23.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
290. layers.24.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
291. layers.24.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
292. layers.24.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
293. layers.24.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
294. layers.24.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
295. layers.24.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
296. layers.24.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
297. layers.24.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
298. layers.24.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
299. layers.24.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
300. layers.24.input_layernorm.weight (å½¢çŠ¶: (1536,))
301. layers.24.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
302. layers.25.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
303. layers.25.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
304. layers.25.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
305. layers.25.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
306. layers.25.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
307. layers.25.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
308. layers.25.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
309. layers.25.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
310. layers.25.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
311. layers.25.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
312. layers.25.input_layernorm.weight (å½¢çŠ¶: (1536,))
313. layers.25.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
314. layers.26.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
315. layers.26.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
316. layers.26.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
317. layers.26.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
318. layers.26.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
319. layers.26.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
320. layers.26.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
321. layers.26.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
322. layers.26.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
323. layers.26.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
324. layers.26.input_layernorm.weight (å½¢çŠ¶: (1536,))
325. layers.26.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
326. layers.27.self_attn.q_proj.weight (å½¢çŠ¶: (1536, 1536))
327. layers.27.self_attn.q_proj.bias (å½¢çŠ¶: (1536,))
328. layers.27.self_attn.k_proj.weight (å½¢çŠ¶: (256, 1536))
329. layers.27.self_attn.k_proj.bias (å½¢çŠ¶: (256,))
330. layers.27.self_attn.v_proj.weight (å½¢çŠ¶: (256, 1536))
331. layers.27.self_attn.v_proj.bias (å½¢çŠ¶: (256,))
332. layers.27.self_attn.o_proj.weight (å½¢çŠ¶: (1536, 1536))
333. layers.27.mlp.gate_proj.weight (å½¢çŠ¶: (8960, 1536))
334. layers.27.mlp.up_proj.weight (å½¢çŠ¶: (8960, 1536))
335. layers.27.mlp.down_proj.weight (å½¢çŠ¶: (1536, 8960))
336. layers.27.input_layernorm.weight (å½¢çŠ¶: (1536,))
337. layers.27.post_attention_layernorm.weight (å½¢çŠ¶: (1536,))
338. norm.weight (å½¢çŠ¶: (1536,))
